<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Polyhedral compilation: part 1 | Emil VATAI </title> <meta name="author" content="Emil VATAI"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="HPC, mcahine learning, mathematics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/lime_logo_sqr.png?291df4c8a7b8dadae1c0a4d405beea96"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://vatai.github.io/blog/2022/polyhedral-compilation-part-1/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Emil</span> VATAI </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Polyhedral compilation: part 1</h1> <p class="post-meta"> Created on January 29, 2022 </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fa-solid fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a>   <a href="/blog/category/compsci"> <i class="fa-solid fa-tag fa-sm"></i> compsci</a>   <a href="/blog/category/polyhedral"> <i class="fa-solid fa-tag fa-sm"></i> polyhedral</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="abstract">Abstract</h1> <p>This blog posts is the first in a series of posts about <strong>polyhedral compilation</strong>, a mathematical model used to describe and reason about certain types of loops, with the aim to generate faster code.</p> <p>This post revisits <a href="https://link.springer.com/article/10.1007/BF01407835" rel="external nofollow noopener" target="_blank">“Some efficient solutions to the affine scheduling problem. I. One-dimensional time” by Paul Feautrier</a>, the seminal paper of the field, which describes how to <em>formulate the the search for an optimal schedule as an integer linear programming (ILP) problem</em>.</p> <h1 id="overview-of-the-process">Overview of the process</h1> <p>Formulated as a source-to-source compilation, the following steps give a (<em>very simplified</em>) overview of the entire process:</p> <ul> <li> <strong>The input</strong> is source code with “nice” loops (where “nice” means that the loops satisfy such properties, that they are simple enough to be handled by ILPs).</li> <li>Problem/step 1: Finding the “nice” loops in the source code. This is handled by <a href="https://repo.or.cz/w/pet.git" rel="external nofollow noopener" target="_blank">Polyhedral Extraction Tool (PET)</a> which extracts affine description of the source code into <a href="https://repo.or.cz/w/isl.git" rel="external nofollow noopener" target="_blank">ISL</a> objects (named integer tuple sets/relations etc.). The loops in the source code can be marked with <code class="language-plaintext highlighter-rouge">scop</code> and <code class="language-plaintext highlighter-rouge">endscop</code> <code class="language-plaintext highlighter-rouge">#pragma</code>s or PET also has an auto-detect feature.</li> <li>Problem/step 2: Find or approximate the dependencies in the code.</li> <li> <strong>Problem/step 3</strong>: Formulate an ILP, which describes the statements from in step 1 and the dependencies from step 2. Given an optimisation objective, the ILP can be solved to find an <strong>(optimal) schedule</strong>.</li> <li>Problem/step 4: Based on the schedule obtained in the previous step <strong>generate</strong> (improved) source code</li> <li> <strong>The output</strong> is a source code with optimised loops.</li> </ul> <p>This post only addresses (the first half) of <strong>Problem/step 3</strong>.</p> <h1 id="example-code-matrix-vector-product">Example code: matrix vector product</h1> <pre><code class="language-C">for (i = 0; i &lt;= n; i++) {
S1: a[i] = 0.0;
    for (j = 0; j &lt;= n; j++)
S2:   a[i] += b[j] * M[i][j];
}
</code></pre> <p>The above code has two relevant <strong>statements</strong> which access the memory: <code class="language-plaintext highlighter-rouge">a[i] = 0.0;</code> labelled as \(S_1\) and <code class="language-plaintext highlighter-rouge">a[i] += b[j] * M[i][j];</code> labelled as \(S_2\). Each of the two statements is executed multiple times, it has multiple <strong>instances</strong>, for example the instances of statement \(S_1\) are:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">a[0] = 0.0;</code> for \(i = 0\),</li> <li> <code class="language-plaintext highlighter-rouge">a[1] = 0.0;</code> for \(i = 1\) etc.</li> </ul> <p>Since instances may need to be described by multiple loop variables, we adopt the notation \(\vec{i}\) for <strong>vectors in the iteration space</strong>, vectors with integer entries, such that the first element corresponds to the outermost and the last to the innermost loop variable. For example</p> <ul> <li> <code class="language-plaintext highlighter-rouge">a[0] += b[1] * M[0][1];</code> for \(\vec{i} = (i, j) = (0, 1)\) and</li> <li> <code class="language-plaintext highlighter-rouge">a[2] += b[3] * M[2][3];</code> for \(\vec{i} = (i, j) = (2, 3)\).</li> </ul> <h1 id="describing-dependencies">Describing dependencies</h1> <h2 id="generalised-dependency-graph-gdg">Generalised Dependency Graph (GDG)</h2> <h3 id="verticesdomains">Vertices/domains</h3> <p>For each statement \(S\) the corresponding <strong>vertex</strong> of the GDG is labelled with the <strong>domain</strong> (hence the \(\mathscr{D}\) notation below) of the statement \(S\), i.e. the subset of the iteration space containing the instances of \(S\) executed by the loop.</p> <ul> <li>\(\mathscr{D}_1 = \\{ i : 0 \le i \le n \\}\) for statement \(S_1\)</li> <li>\(\mathscr{D}_2 = \\{ (i, j) : 0 \le i, j \le n \\}\) for statement \(S_2\)</li> </ul> <p>Technically, the domains are not sets, but families of sets, depending on parameters (in this example on the single parameter \(n\)), so the domain for statement 1 is the map \(n \mapsto \\{ i : 0 \le i \le n \\}\), but we omit the “\(n \mapsto\)” part, and treat \(n\) as a constant (but this will be included in a more).</p> <h3 id="edgesdependencies">Edges/dependencies</h3> <p>The <strong>edges</strong> of GDG are the <strong>dependencies</strong> between two statements and are labelled with a subset of the direct product (a relation, hence the \(\mathscr{R}\) notation below) between the two domains of statements of the start and end of the edge, that is, if \(S'\) and \(S\) are two statements and there is a dependency between the instances \(\vec{i'} \in \mathscr{D}_ {S'}\) and \(\vec{i} \in \mathscr{D}_ S\) then there is and edge from vertex \(\mathscr{D}_{S'}\) to \(\mathscr{D} _S\) labelled with a set that contains \((\vec{i'}, \vec{i})\).</p> <p>A simplified (ergo very conservative) dependency analysis (there are programs which can perform such analysis) could yield two dependencies:</p> <ul> <li>\(\mathscr{R}_{1, 2} = \{ \bigl( i', (i, j) \bigr) : i' = i \}\) describes the dependency between \(S_1\) and \(S_2\) which requires for the initialisation in \(S_1\) (<code class="language-plaintext highlighter-rouge">a[i] = 0.0</code>) to precede (all instances of) statement \(S_2\) when the two statements share the same value for the loop variable \(i\) (hence \(i' = i\)).</li> <li>\(\mathscr{R}_{2, 2} = \{ \bigl( (i', j'), (i, j) : i' = i \land j' &lt; j \}\) describes the dependency of \(S_2\) on itself, which requires, for a given \(i\) (\(i' = i\)) the earlier instances of (in \(j\)) are executed before the later instances (hence \(j' &lt; j\)).</li> </ul> <p>This dependency analysis is <strong>very</strong> coarse and/or conservative (read poor), we’ll discuss a simple data flow dependency later (which is still quite simple, but a slight improvement over the one above).</p> <h2 id="detailed-dependency-graph-ddg">Detailed Dependency Graph (DDG)</h2> <p>The GDG is structured: the vertices in GDG are statements, and these statements represent multiple instances, but we actually care about the dependencies between the instances. For this reason the Detailed Dependency Graph “flattens” the graph, and every vertex is an instance of a statement, and the edges are the dependencies between these instances.</p> <h3 id="vertices">Vertices</h3> \[\Omega = \bigcup _{S \in V} \{ (S, \vec{i}) : \vec{i} \in \mathscr{D} _S \}\] <h3 id="edges">Edges</h3> \[\Gamma = \bigcup _{e \in E} \bigl\{ \bigl( (\sigma(e), \vec{i'}), (\delta(e), \vec{i}) \bigr) : \vec{i'} \in \mathscr{D} _{\sigma(e)}, \vec{i} \in \mathscr{D} _{\delta(e)}, (\vec{i'}, \vec{i}) \in \mathscr{R}_e \bigr\}\] <p>where the statement \(\sigma(e)\) is the start, statement \(\delta(e)\) is the end of edge \(e\) (of the GDG).</p> <h1 id="schedule">Schedule</h1> <p>The schedule is a map \(\theta: \Omega \to \mathbb{R}_0^+\) from the set of instances to some non-negative value which is the “date” (or timestamp, or time) of the instance.</p> <h2 id="generating-code">Generating code</h2> <p>As mentioned above, generating code is a separate, and very much non-trivial problem. But to get a better feeling how to interpret the schedule \(\theta\) a simplified code generations is presented:</p> <p>Let \(\mathtt{F}(t) = \\{ (S, \vec{i}) \in \Omega: \theta(S, \vec{i}) = t \\}\), i.e. the set of all instances of all statements which should be executed at time step \(t\). Let \(\mathtt{L} = \max_{(S, \vec{i}) \in \Omega} \theta(S, \vec{i})\).</p> <pre><code class="language-C++">for (t = 0; t &lt;= L; t++) {
  #pragma omp parallel
  for (inst : F(t))
    execute(inst);
  barrier();
}
</code></pre> <p>Of course, actual code generation is a much harder task than this naive pseudo-code, but it can be handled separately, the objective of this now is how to obtain the optimal schedule.</p> <h2 id="there-is-no-optimal-schedule">There is (no) optimal schedule</h2> <p>The paper cites Theorems which say that finding a schedule <strong>of arbitrary form</strong> is an undecidable problem. Because of this, we restrict ourselves to <strong>affine schedules</strong>, that is schedules of the form: \(\theta(S, \vec{i}) = \tau_S \vec{i} + \sigma_s \vec{n} + \alpha_s\) for each statement \(S\). The vector \(\vec{n}\) is the vector of parameters, for the example above the vector of length 1 containing \(n\). In this case the triplet \((\tau_S, \sigma_S, \alpha_S)\) completely define \(\theta\) (for a given \(S\)), so the goal is finding a \((\tau_S, \sigma_S, \alpha_S)\) triplet for each statement \(S\).</p> <h1 id="more-advanced-dependency-analysis">More advanced dependency analysis</h1> <h2 id="depth">Depth</h2> <p>Descriptions such as GDG and DDG can enable some optimisations.</p> <p>The <strong>depth</strong> of an edge is the position until which both instances at the start and the end of the edge share values, and after which the end instance has a larger value, that is \(p_ e\) is the depth of edge \(e\) iff \((\vec{i'}, \vec{i}) \in \mathscr{R} _ e\) and \(i'_ k = i_ k\) for \(1 \le k \le p_ e\) and \(i'_ {p_ e} &lt; i_ {p_ e}\) where \(\vec{i'} = (i'_ 1, i'_ 2, \ldots)\) and \(\vec{i} = (i_ 1, i_2, \ldots)\).</p> <p>In the example, both edges of the GDG have depth 1:</p> <ul> <li>\(\mathscr{R}_{1, 2} = \{ \bigl( i', (i, j) \bigr) : i' = i \}\),</li> <li>\(\mathscr{R}_{2, 2} = \{ \bigl( (i', j'), (i, j) : i' = i \land j' &lt; j \}\).</li> </ul> <p>In both cases the \(i'=i\) part implies depth \(p_e \ge 1\) and the rest ensures \(p _e \le 1\).</p> <p>This can be used to infer, that we are allowed to execute the outermost loop in parallel.</p> <h2 id="dependence-direction-vectors">Dependence direction vectors</h2> <p>A more detailed description of the dependencies can be given using symbols such as \(&lt;, \le, =, *, \ldots\) combined in a <strong>dependence direction vector</strong> (the asterisk denotes a wildcard, meaning any relation). Depth can be expressed with DDVs as</p> \[(\overbrace{=, \ldots, =}^{p_e}, &lt;, *, \ldots)\] <h2 id="uniform-dependence">Uniform dependence</h2> <p>The case where there is a constant difference between the instances of both ends of an edge, that is when \(i' = i + d\) if \((i', i) \in \mathscr{R}_ e\), the edge \(e\) is said to have a <strong>uniform dependence</strong>. In this case, instead of keeping track of \(\mathscr{D}_ {\sigma(e)}\), \(\mathscr{D}_ {\delta(e)}\) and the set of \((\vec{i'}, \vec{i})\) pairs, we can just keep track of a single set (polyhedron) of instances \(\mathscr{P}_ e\) and a affine map \(h_ e\) such that \(y \in \mathscr{P}_ e \implies y \in \mathscr{D}_ {\delta(e)} \land h_e(y) \in \mathscr{D} _{\sigma(e)}\) and then</p> \[(\vec{i'}, \vec{i}) \in \mathscr{R}_ e \iff \vec{i'} = h_ e(\vec{i}) \land \vec{i} \in \mathscr{P}_e\] <p>A more detailed analysis shows that the second edge of our example has such a uniform dependency.</p> <h2 id="dataflow-analysis">Dataflow analysis</h2> <p>A little more advanced (but still very much conservative) dataflow analysis can further restrict the polyhedrons \(\mathscr{R} _{1, 2}\) and \(\mathscr{R} _{2, 2}\). The analysis of the memory reads and writes tells us that only the entries of <code class="language-plaintext highlighter-rouge">a[i]</code> updated, they are updated independently for each index \(i\), and making no assumptions about the <code class="language-plaintext highlighter-rouge">+</code> operation (such as associativity, which <em>could</em> be used for further optimisations), we observe that</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">a[i]</code> is initialised in statement \(S_ 1\) and only the first iteration of the \(j\) loop depends on it: \(\bigl(i', (i, j) \bigr) \in \mathscr{R}_ {1,2} \iff i' = i \land j = 0\) (I think there is a typo in the paper saying \(j = 1\)?). This is reduced as:</p> \[\mathscr{P}_ {e _1} = \mathscr{D}_2 \cap \{ (i, j) : j \le 0 \}, \quad h _{e _1}(i, j) = i\] </li> <li> <p><code class="language-plaintext highlighter-rouge">a[i]</code> is updated with each iteration of \(j\), so every iteration (instance) of \(j\) depends only on the previous iteration (\(j - 1\)), and this only applies starting from the second iteration (\(j \ge 1\)): \(\bigl( (i', j'), (i, j) \bigr) \in \mathscr{R} _{2,2} \iff i' = i \land j' = j - 1 \land j \ge 1\) (Again, this might be a typo \(j \ge 2\) in the paper?) This is reduced as:</p> \[\mathscr{P} _{e _2} = \mathscr{D} _2 \cap \{ (i, j) : j \ge 1 \}, \quad h _{e _2}(i, j) = (i, j - 1)\] </li> </ul> <p>We will continue with these reduced forms.</p> <h1 id="formulating-the-integer-linear-program">Formulating the integer linear program</h1> <h2 id="describing-verticesdomains">Describing vertices/domains</h2> <p>The \(\mathscr{D}_ S\) domains (including the parameters, represented as \(\vec{n}\)) need to be rewritten in the form where given the parameters \(\vec{n}\) the instance \(\vec{i}\) is in domaind \(\mathscr{D} _S\) iff:</p> \[a_{S_k} \begin{pmatrix} \vec{i} \\ \vec{n} \end{pmatrix} + b_{S_k} \ge 0 \quad (\forall k=1, \ldots m_S)\] <p>This way, the \((a_ {S_ k}, b_ {S_ k})\) pairs completely describe \(\mathscr{D} _S\) (that is, you can use these vectors to represent them in a computer program).</p> \[\begin{align} \mathscr{D}_1 &amp;= \{ i : 0 \le i \le n \} \\&amp;= \{ i : 0 \le i \land 0 \le n - i \} \\ \mathscr{D}_2 &amp;= \{ (i, j) : 0 \le i, j \le n \} \\ &amp;= \{ (i, j) : 0 \le i \land 0 \le n - i \land 0 \le j \land 0 \le n - j \} \end{align}\] <p>In the example of \(\mathscr{D} _1\) there are two inequalities, implying \(m _1 = 2\):</p> \[0 \le i = (1, 0) \begin{pmatrix} i \\ n \end{pmatrix} + 0\] <p>implies \(a _{S _1} = (1, 0)\) and \(b _{S _1} = 0\) and</p> \[0 \le n - i = (-1, 1) \begin{pmatrix} i \\ n \end{pmatrix} + 0\] <p>implies \(a _{S _2} = (-1, 1)\) and \(b _{S _2} = 0\).</p> <p>Domain \(\mathscr{D} _2\) can be described with \(m _2 = 4\) such equations.</p> <h2 id="describing-edgesdependencies">Describing edges/dependencies</h2> <p>The edges \(\mathscr{R}_ e\) of the GDG is described by \((c_e, d_e)\) such that:</p> \[c _{e _k} \begin{pmatrix} \vec{i'} \\ \vec{i} \\ \vec{n} \end{pmatrix} + d_ {e_k} \ge 0 \quad (\forall k=1, \ldots m _e)\] <p>or for a restricted schedule with the affine map \(\vec{i'} = h_e(\vec{i})\) and the rewritten reduced domain \(\mathscr{P} _e\):</p> \[c_{e_k} \begin{pmatrix} \vec{i} \\ \vec{n} \end{pmatrix} + d_{e_k} \ge 0 \quad (\forall k=1, \ldots m_S)\] <p>The reduced domains \(\mathscr{P} _{e _1}\) and \(\mathscr{P} _{ e _2}\) can be described similarly as the other domains \(\mathscr{D} _1\) and \(\mathscr{D} _2\).</p> <h2 id="describing-schedules">Describing schedules</h2> <p>The schedule \(\theta(S, \vec{i})\) is also going to be rewritten using a set of \(\mu\) Farkas multipliers. For each statement \(S\) we assume that the schedule can be expressed as:</p> \[\theta(S, \vec{i}) \equiv \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \Bigl( a_{S_k} \begin{pmatrix} \vec{i} \\ n \end{pmatrix} + b_{S_k} \Bigr)\] <p>This captures the information provided by the domains \(\mathscr{D} _S\) captured in the (\(m _S\) number of) \((a _{S _k}, b _{S _k})\) pairs. To combine this with the information from the dependencies/edges we will need the <em>delay</em> corresponding to the edges.</p> <h2 id="the-delay">The delay</h2> <p>We assume that if the instance \(\vec{i}\) of a statement \(S\) depends on the instance \(\vec{i'}\) of the statement \(S'\), then there is a <strong>delay</strong> \(\Delta\) associated with that dependency/edge \(e\). This means that the date of \(S, \vec{i}\) assigned by the schedule \(\theta\) is greater (by at least \(1\)) than the date of \(S', \vec{i'}\):</p> \[\Delta = \theta(S, \vec{i}) - \theta(S', \vec{i'}) - 1 \ge 0\] <p>We assume that this delay can be rewritten with a different set of \(\lambda\) Farkas multipliers (these will be just placeholders to express dependencies between inequalities across inequalities resulting from the dependencies/edges).</p> \[\Delta \equiv \lambda_{e_0} + \sum_{k=1}^{m_e} \lambda_{e_k} \Bigl( c_{e_k} \begin{pmatrix} \vec{i} \\ n \end{pmatrix} + d_{e_k} \Bigr)\] <h1 id="putting-it-all-together">Putting it all together</h1> <p>The \(\equiv\) in the last equation was alluding to the next step where we combine the “\(\theta\) equations” expressing the domains and the “\(\Delta\) equations” expressing the dependencies.</p> \[\theta(S, \vec{i}) - \theta(S', \vec{i'}) - 1 \equiv \Delta \ge 0\] <p>On the left side of \(\equiv\) in the expression above we use two instances of the “\(\theta\) equations” (with \(a _S{ _k}\), \(b _S{ _k}\) and \(\mu _S{ _k}\)), on the right “\(\Delta\) equations” (with \(c _{e _k}\), \(d _{e _k}\) and \(\lambda _{e _k}\)) and solve the ILP for the \(\mu _{S _k}\) variables (for each statement \(S\)).</p> <h2 id="edge-e_1--1-to-2">Edge \(e_1 : 1 \to 2\)</h2> <p>For the first edge \(e _1\) between statement \(S_1\) to \(S_2\) the equations from above give rise to the following</p> \[\begin{align*} &amp;\bigl[\mu_{2, 0} + \mu_{2, 1} i + \mu_{2, 2} (n - i) + \mu_{2, 3} j + \mu_{2, 4} (n - j) \bigr] \\ -&amp; \bigl[\mu_{1, 0} + \mu_{1, 1} i + \mu_{1, 2} (n - i) \bigr] - 1 \\ \equiv&amp; \lambda_{1, 0} + \lambda_{1, 1} i + \lambda_{1, 2} (n - i) + \lambda_{1, 3} j + \lambda_{1, 4} (n - j) - \lambda_{1, 5} j \ge 0 \end{align*}\] <p>The first and second line (except the \(-1\) at the end of it) of the ILP come from the rewritten form of \(\mathscr{D}_2\) and \(\mathscr{D}_1\) from the <a href="#describing-verticesdomains">Describing vertices/domains</a> section, plugged in the “\(\Theta\) equation”, while the third line is the result of taking \(\mathscr{P} _{e _1}\) <a href="#dataflow-analysis">Dataflow analysis</a>, which is \(-j \ge 0\) and the inequalities from the \(\mathscr{D} _2\) (hence the similarity to the first line).</p> <p>The previous equation is equivalent to the following system of equations by equating the coefficients of \(i\), \(j\), \(n\) and the constant term.</p> \[\begin{align} \mu_{2, 0} - \mu_{1, 0} - 1 &amp;= \lambda_{1, 0} &amp;\text{const. terms}\\ \mu_{2, 1} - \mu_{2, 2} - \mu_{1, 1} + \mu_{1, 2} &amp;= \lambda_{1, 1} - \lambda_{1, 2} &amp;\text{$i$ terms}\\ \mu_{2, 3} - \mu_{2, 4} &amp;= \lambda_{1, 3} - \lambda_{1, 4} - \lambda_{1, 5} &amp;\text{$j$ terms}\\ \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} &amp;= \lambda_{1, 2} + \lambda_{1, 4} &amp;\text{$n$ terms} \end{align}\] <h2 id="edge-e_2--2-to-2">Edge \(e_2 : 2 \to 2\)</h2> <p>The second edge is a <a href="#uniform-dependence">uniform dependency</a>, the schedule for the start and end of the edge, \(\theta(S _2, h(\vec{i}))\) and \(\theta(S _2, \vec{i})\) is nearly identical (difference highlighted in the formulae below).</p> \[\mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k} (\begin{smallmatrix} {\color{magenta}{\vec{i}}} \\ n \end{smallmatrix}) + b_{S_k} \bigr) - \bigl[ \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k} (\begin{smallmatrix} \color{magenta}{h(\vec{i})} \\ n \end{smallmatrix}) + b_{S_k} \bigr) \bigr]\] <p>This results to most of the terms cancelling each other out in the expression \(\theta(S _2, \vec{i}) - \theta(S _1, h(\vec{i}))\) (written with the \(\mu _{S _k}\) Farkas multipliers):</p> \[\mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k} \Bigl(\begin{smallmatrix} i \\ j \\ n \end{smallmatrix}\Bigr) + b_{S_k} \bigr) - \bigl[ \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k} \Bigl(\begin{smallmatrix} i \\ j \color{magenta}{-1} \\ n \end{smallmatrix}\Bigr) + b_{S_k} \bigr) \bigr]\] <p>As a result, the loop edge on \(S _2\) results in the following equation (not the lack of \(\lambda _{S _k}\) multipliers).</p> \[\Delta = \theta(S _2, i, j) - \theta(S _2, i, j - 1) - 1 = \mu_{2, 3} - \mu_{2, 4} - 1 \ge 0\] <h2 id="the-calculations">The calculations</h2> <p>Collecting and rearranging the inequalities for \(e _1 : S _1 \to S _2\) and \(e _2 : S _2 \to S _2\).</p> \[\begin{align} \lambda_{1, 0} =&amp; \mu_{2, 0} - \mu_{1, 0} - 1 \ge 0 \\ \lambda_{1, 1} =&amp; \mu_{2, 1} + \mu_{2, 4} - \mu_{1, 1} - \lambda_{1, 4} \ge 0 \\ \lambda_{1, 3} =&amp; \mu_{2, 3} - \mu_{2, 4} - \lambda_{1, 4} - \lambda_{1, 5} \ge 0 \\ \lambda_{1, 2} =&amp; \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} - \lambda_{1, 4} \ge 0 \\ &amp; \mu_{2, 3} - \mu_{2, 4} - 1 \ge 0 \end{align}\] <p>Simplifying it gives:</p> \[\begin{align*} \mu_{2, 0} - \mu_{1, 0} - 1 \ge&amp; 0 \\ \mu_{2, 3} - \mu_{2, 4} - 1 \ge&amp; 0 \\ \mu_{2, 3} + \mu_{2, 4} - \mu_{1, 1} \ge&amp; 0 \\ \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} \ge&amp; 0 \end{align*}\] <p>All these manipulations can be performed by algorithms automatically.</p> <h2 id="one-possible-result">One possible result</h2> <p>One valid choice for the \(\mu _{S _k}\) values is:</p> <ul> <li> \[\mu_{1, 0} = \mu_{2, 1} = \mu_{2, 2} = \mu_{2, 4} = \mu_{1, 1} = \mu_{1, 2} = 0\] </li> <li> \[\mu_{2, 0} = \mu_{2, 3} = 1\] </li> <li> \[\theta(1, i) = 0\] </li> <li> \[\theta(2, i, j) = j + 1\] </li> </ul> <h2 id="generated-code">Generated code</h2> <p>The resulting schedule is:</p> <ul> <li> \[\theta(S _1, i) = 0\] </li> <li> \[\theta(S _2, i, j) = j + 1\] </li> </ul> <p>Generating code from this is a separate task and will be disucussed in the next blog post, but the paper suggests something similar to:</p> <pre><code class="language-C++">#pragma omp parallel
for (i = 0; i &lt;= n; n++)
  a[i] = 0.0;
for (j = 0; j &lt;= n; j++)
  #pragma omp parallel
  for (i = 0; i &lt;= n; i++)
    a[i] += b[j] * M[i][j];
</code></pre> <h1 id="citing-this-blog-post">Citing this blog post</h1> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{vatai2022polytutor1,
  title={Polyhedral compilation: part 1},
  url={https://vatai.github.io/math/compsci/polyhedral/polyhedral-compilation-part-1/},
  author={Vatai, Emil},
  year={2022},
  month={Feb}
}
</code></pre></div></div> <h1 id="feedback">Feedback</h1> <p>Feedback is very much welcome. I don’t have a comment section set up, but you can raise an <a href="https://github.com/vatai/vatai.github.io/issues" rel="external nofollow noopener" target="_blank">issue</a> on GitHub.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/scoping-snap/">[draft] SCoPing SNAP</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mpi4py-with-slurm/">MPI4py under Slurm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/making-tadashi-into-a-python-package/">Making Tadashi into a Python package</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/photo-gallery/">a post with image galleries</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/flattening-loops-again/">[DRAFT] Flattening loops of combinations, again!?</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'vatai/vatai.github.io',
        'data-repo-id': 'R_kgDONJ_lqg',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDONJ_lqs4CkI6M',
        'data-mapping': 'pathname',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'top',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Emil VATAI. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. <a href="https://vatai.github.io/">Impressum</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-XYQ6LJR0NX"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-XYQ6LJR0NX');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>