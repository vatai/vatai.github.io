<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://vatai.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://vatai.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-08T23:58:51+00:00</updated><id>https://vatai.github.io/feed.xml</id><title type="html">blank</title><subtitle>Homepage of Emil VATAI, HPC/ML research scientist@Riken R-CCS </subtitle><entry><title type="html"></title><link href="https://vatai.github.io/blog/2025/2025-11-20-tadashi-with-cython/" rel="alternate" type="text/html" title=""/><published>2025-12-08T23:58:51+00:00</published><updated>2025-12-08T23:58:51+00:00</updated><id>https://vatai.github.io/blog/2025/2025-11-20-tadashi-with-cython</id><content type="html" xml:base="https://vatai.github.io/blog/2025/2025-11-20-tadashi-with-cython/"><![CDATA[ <p>This post is basically me <a href="https://blog.codinghorror.com/rubber-duck-problem-solving/">rubber-ducking</a> how I should refactor <a href="/projects/tadashi">Tadashi</a> <a class="citation" href="#vatai2025tadashi">(Vatai et al., 2025)</a> to include LLVM/Polly backend (which would enable fortran support). I’ll try to list the requirements focusing on the Python-C/C++ interface.</p> <p>We need a <em>Python</em> interface to specify the C input program and the backend, and it should return a <em>Python</em> object which we’ll use for:</p> <ul> <li>querying transformations</li> <li>executing transformations</li> <li>generating transformed code</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">app</span> <span class="o">=</span> <span class="nc">App</span><span class="p">(</span><span class="sh">"</span><span class="s">source.c</span><span class="sh">"</span><span class="p">,</span> <span class="n">backendPET</span><span class="p">)</span>
<span class="c1"># list[scop] = backendPET("sources.")
# pet: run transform fn (in C)
# llvm: run clang (both) and collect schedule (in C)
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node</span> <span class="o">=</span> <span class="n">app</span><span class="p">.</span><span class="n">scops</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">schedule_tree</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
<span class="c1"># locate node (in C, in scop)
</span>
<span class="n">legal</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="c1"># transform, (in C, in scop)
</span>
<span class="n">tapp</span> <span class="o">=</span> <span class="n">app</span><span class="p">.</span><span class="nf">gencode</span><span class="p">()</span>
<span class="c1"># pet: run again transofm(list[pet_scop*])
# llvm: write scop-&gt;json and run clang
</span>
<span class="n">tapp</span><span class="p">.</span><span class="nf">measure</span><span class="p">()</span>
<span class="c1"># 100% in pyhon
</span></code></pre></div></div> <pre><code class="language-mermaid">sequenceDiagram
  participant M as ml_model.py
  participant A as app.py
  participant T as translator.py
  M-&gt;&gt;A: ("source.c", translator{PET/LLVM})
  A-&gt;&gt;T: "source.c"
  T-&gt;&gt;A: `list[Scop]`
</code></pre> <p> </p> <p> </p> <p> </p> <p> </p>]]></content><author><name></name></author></entry><entry><title type="html">CIBuildWheel is DA BOMB!</title><link href="https://vatai.github.io/blog/2025/cibuildwheel-is-da-bomb/" rel="alternate" type="text/html" title="CIBuildWheel is DA BOMB!"/><published>2025-11-18T23:30:00+00:00</published><updated>2025-11-18T23:30:00+00:00</updated><id>https://vatai.github.io/blog/2025/cibuildwheel-is-da-bomb</id><content type="html" xml:base="https://vatai.github.io/blog/2025/cibuildwheel-is-da-bomb/"><![CDATA[<p>After the last submission of our <a href="/projects/tadashi">Tadashi</a> paper <a class="citation" href="#vatai2025tadashi">(Vatai et al., 2025)</a>, one of the reviewers complained about installing Tadashi is similarly cumbersome as installing PET or ISL (which I also struggled with in the beginning and can relate to). So, to solve this problem, yesterday I spent the whole day hacking and trying to figure out <a href="https://cibuildwheel.pypa.io/en/stable/">CIBuildWheel</a> and I’m really happy with what I found! <strong>TL;DR: With CIBuildWheel we should be able to upload Tadashi to PyPI and have <code class="language-plaintext highlighter-rouge">pip install tadashi</code> fully working.</strong></p> <p>In the current setup, we can use <code class="language-plaintext highlighter-rouge">pip install git+https://github.com/vatai/tadashi.git</code>, which, in theory would take care of everything, however, in practice, since it is building PET and ISL in the background, this can go wrong if some dependencies are not installed. CIBuildWheel<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> solves this problem by building the extensions<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> in isolation and packaging them into a wheel<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>.</p> <p>Obviously, <strong>the problem with binary packages is portability</strong>! And I’m not just talking about Linux vs Windows, but also withing Linux, a binary built on one Linux may not work on another Linux. To solve this, CIBuildWheel uses something called <a href="https://github.com/pypa/manylinux">manylinux</a>. As I understand, to the user (package maintainer), manylinux a set of Docker images, with somewhat standard (read older) glibc and other libraries, so that if you compile against those libraries, you cover a lot of systems. Also there are multiple manylinux Docker images, covering different versions of different libraries. CIBuildWheel builds wheels in these Docker containers and by default generates <a href="https://github.com/vatai/complicated-project-with-extension/actions/runs/19494788268">these</a> Linux wheels (look at the filenames, the <code class="language-plaintext highlighter-rouge">cpXYY</code> indicates the Python version X-YY, and the rest of the name includes which manylinux was used – it’s a deep rabbit hole and I’ll stop here with the explanation). In theory it could generate wheels for Windows and Mac too :shrug:.</p> <h1 id="prototyping">Prototyping</h1> <p>Before going “all in” to apply this to Tadashi, I made a PoC repo (called <a href="https://github.com/vatai/complicated-project-with-extension">Complicated project with extensions</a>, or <code class="language-plaintext highlighter-rouge">cpwe</code> for short) to test the critical parts (i.e., parts I didn’t quite understand) of this setup. This also included Cython integration, the new approach I plan to implement to interface the PET/ISL libraries with Python (instead of SWIG, which I currently use). Cython is not just a more “pythonic” approach, it also simplifies many things both in Tadashi’s code and in the build process.</p> <h2 id="the-goals">The goals</h2> <p>I originally intended to cover (a simplified version of) everything including uploading binary packages to PyPI, and test <code class="language-plaintext highlighter-rouge">pip install cpwe</code>, but then I realised I can do things locally: When I saw all the wheels (<code class="language-plaintext highlighter-rouge">.whl</code> files) created by CIBuildWheel, I realised PyPI most likely just stores these <code class="language-plaintext highlighter-rouge">.whl</code> files and <code class="language-plaintext highlighter-rouge">pip install cpwe</code> probably just selects the appropriate <code class="language-plaintext highlighter-rouge">.whl</code> file, downloads it, and installs it, which can also simulated locally with <code class="language-plaintext highlighter-rouge">pip install the_appropriate_wheel.whl</code>!</p> <p>One goal was to <strong>set up GitHub actions to generate all the wheels automatically</strong>. This was easy to achieve following the <a href="https://cibuildwheel.pypa.io/en/stable/ci-services/">CIBuildWheel docs</a> and also easy to verify, bacause the example in the docs uploaded all the wheels as <a href="https://github.com/vatai/complicated-project-with-extension/actions/runs/19494788268">artifacts</a>. These wheels would then be uploaded via GH actions (using twine) to PyPI, something I already implemented in <a href="/projects/radicalpy">another project</a>.</p> <p>The other, more important, goal was <strong>making a wheel which includes binaries from a separate C library</strong>, i.e. has Python code which calls functions from a C library (i.e., ISL). I should elaborate.</p> <h2 id="getting-the-right-wheels">Getting the right wheels</h2> <p>To summarise, we want to</p> <ul> <li>build a Python extension,</li> <li>using Cython,</li> <li>which would be calling a third party C library (namely ISL).</li> </ul> <h3 id="extensions-the-simple-case">Extensions: The simple case</h3> <p>Most of the docs describe Cython extensions (or SWIG extensions for that matter) as standalone code, that are converted into C/C++ code and then built into an <code class="language-plaintext highlighter-rouge">.so</code> file. It looks something like this:</p> <pre><code class="language-mermaid">flowchart LR
    Cython["Cython foo.py or foo.pyx files"]
    C["Generated foo.c or foo.cpp files"]
    SO["Compiled foo.so binary file"]
    Cython --&gt; C --&gt; SO
    style C fill:#ff0,color:#000
    style SO fill:#f9f,color:#000
</code></pre> <p>And that final <code class="language-plaintext highlighter-rouge">foo.so</code> file has all the code you need! So the dependencies are simple:</p> <pre><code class="language-mermaid">---
title: "Cython extensions: the simple case"
---
classDiagram
    direction LR
    PythonPackage &lt;|-- Extension
    class PythonPackage{
      +cpwe.py Python files
      +build_from_pyproject_toml()
    }
    class Extension{
      +foo.pyx Cython files
      +cythonize_in_setup_py()
    }
</code></pre> <h3 id="extensions-with-dependencies">Extensions with dependencies</h3> <p>However our situation is more complicated: Our <code class="language-plaintext highlighter-rouge">foo.so</code> has an extra dependency (ISL), which itself pulls in other dependencies (namely GMP) which are not necessary installed on the end-user’s system.</p> <pre><code class="language-mermaid">---
title: "Cython extensions with a dependencies"
---
classDiagram
    direction LR
    PythonPackage &lt;|-- Extension
    Extension &lt;|-- Dependency
    Dependency &lt;|-- Lv2Dependency
    class PythonPackage{
      +cpwe.py Python files
      +build_from_pyproject_toml()
    }
    class Extension{
      +foo.pyx Cython files
      +cythonize_in_setup_py()
    }
    class Dependency{
      +isl.c files
      +build_with_make()
    }
    class Lv2Dependency{
      +GMP system package
      +apt_install()
    }
</code></pre> <p>And this is why CIBuildWheel is <em>DA BOOOOMB</em>! It takes care of all this!</p> <p>These are the relevant parts of the <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file that configures the whole project:</p> <figure class="highlight"><pre><code class="language-toml" data-lang="toml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="nn">[build-system]</span>
<span class="py">requires</span> <span class="p">=</span> <span class="p">[</span><span class="s">"setuptools"</span><span class="p">,</span> <span class="s">"cython"</span><span class="p">,</span> <span class="s">"cibuildwheel"</span><span class="p">]</span>
<span class="py">build-backend</span> <span class="p">=</span> <span class="s">"setuptools.build_meta"</span>

<span class="nn">[tool.cibuildwheel]</span>
<span class="py">build-frontend</span><span class="p">=</span><span class="s">"build[uv]"</span>
<span class="py">before-all</span> <span class="p">=</span> <span class="p">[</span><span class="s">"./third_party/install.sh"</span><span class="p">]</span>
<span class="c"># build = "cp313-manylinux_x86_64"</span>
<span class="c"># manylinux-x86_64-image = "manylinux-mod"</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>In line 2 we list <code class="language-plaintext highlighter-rouge">cibuildwheel</code> as a build dependency (it can just be <code class="language-plaintext highlighter-rouge">pip install</code>ed as any other Python package).</p> <p>The block from line 5 covers the <code class="language-plaintext highlighter-rouge">cibuildwheel</code> specific settings. Setting the frontend to use <code class="language-plaintext highlighter-rouge">uv</code> potentially speeds up the build process. And finally <strong>the <code class="language-plaintext highlighter-rouge">before-all</code> allows us to call a script which builds our dependency, i.e. ISL</strong>.</p> <p>The commented out lines were <strong>hacks to speed up debugging</strong>.</p> <ul> <li>The <code class="language-plaintext highlighter-rouge">build</code> field specifies which wheels should be build (uncommenting line 8 would produce only the wheel built agains Python 3.13 and <code class="language-plaintext highlighter-rouge">manylinux_x86_64</code>).</li> <li>The <code class="language-plaintext highlighter-rouge">manylinux-x86_64-image</code> field specifies the Docker image to be used for <code class="language-plaintext highlighter-rouge">manylinux-x86_64</code>. I created a custom Docker image with ISL prebuilt which sped up testing by skipping both downloading the GMP system packages from the Alma Linux repo, and building ISL from source. For this I obviously disabled the <code class="language-plaintext highlighter-rouge">install.sh</code> script in <code class="language-plaintext highlighter-rouge">before-all</code>.</li> </ul> <h2 id="verification">Verification</h2> <p>To verify that everything works as Intended I wrote a small <a href="https://github.com/vatai/complicated-project-with-extension/blob/main/tests/test_local_uv_project_from_scratch.sh">test script</a>. The main steps of the script were the following:</p> <ol> <li>Call <code class="language-plaintext highlighter-rouge">uvx cibuildwheel</code>, which simulates what happens in the GH action and builds the <code class="language-plaintext highlighter-rouge">.whl</code> files locally.</li> <li>Create a temporary Python project, with <code class="language-plaintext highlighter-rouge">uv</code>.</li> <li>Installing the <code class="language-plaintext highlighter-rouge">cpwe</code> package, i.e., newly generated<code class="language-plaintext highlighter-rouge">.whl</code> file in the project’s <code class="language-plaintext highlighter-rouge">venv</code>.</li> <li>Running code which invokes <code class="language-plaintext highlighter-rouge">cpwe</code> so it calls ISL functions.</li> </ol> <p><code class="language-plaintext highlighter-rouge">uv</code> is used out of convenience to automate the process of creating a <code class="language-plaintext highlighter-rouge">venv</code>, activating the <code class="language-plaintext highlighter-rouge">venv</code>, installing a wheel to the <code class="language-plaintext highlighter-rouge">venv</code>, running a python script in the <code class="language-plaintext highlighter-rouge">venv</code> and disabling the <code class="language-plaintext highlighter-rouge">venv</code>. Both the directories where wheels are created (step 1) and the directory where the <code class="language-plaintext highlighter-rouge">uv</code> project is created (step 2) are delete and regenerated from scratch every time the script executes.</p> <h2 id="additional-verification">Additional verification</h2> <p>I used the process described above as a quick indicator whether things are working or not. To simulate installing and running the code in the package on a random computer, i.e., to double check that CIBuildWheel actually builds a wheel that has all the code required to be executed on any system (without any dependency outside of the Python ecosystem), I spun up an clean Ubuntu container, I copied the appropriate <code class="language-plaintext highlighter-rouge">.whl</code> file to it, installed <code class="language-plaintext highlighter-rouge">uv</code> and some other Python packages, and executed a similar script as above. This confirmed that it worked on any system, even if it didn’t have GMP or ISL installed.</p> <p>I looked inside the <code class="language-plaintext highlighter-rouge">venv</code> after installing the wheel to see how this is achieved. Inside the <code class="language-plaintext highlighter-rouge">site-packages</code> I found the following files:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── cpwe
│   ├── foo.c # C code (generated by Cython)
│   ├── foo.cpython-313-x86_64-linux-gnu.so #!!! .so file (built from the C code)
│   ├── foo.py # source containing Cython code (written by me)
│   └── isl.pxd # Cython "header" file to declaring the ISL functions (written by me)
...
├── cpwe.libs
│   ├── libgmp-d944b113.so.10.3.2  manylinux container #!!! .so copied from the system package within the
│   └── libisl-8ba7b133.so.23.4.0 #!!! .so file built in the container


</code></pre></div></div> <p>CIBuildWheel added all the relevant <code class="language-plaintext highlighter-rouge">.so</code> files: the <code class="language-plaintext highlighter-rouge">foo.cython*.so</code> generated from my Cython code in <code class="language-plaintext highlighter-rouge">foo.py</code> (which would be the only file if this were the simple case) and the <code class="language-plaintext highlighter-rouge">libisl*.so*</code> which was Cython extension’s dependency, and <code class="language-plaintext highlighter-rouge">libgmp*.so*</code> which was <code class="language-plaintext highlighter-rouge">libisl*.so*</code>’s dependency. :tada::tada::tada:</p> <h2 id="future-work">Future work</h2> <p>For now, this really was a minimal working example for building portable wheel packages, and only included ISL as a dependency. I need to see if this works also for PET which includes LLVM as a dependency – which is <em>slightly</em> larger than GMP. :cold_sweat:</p> <p>In a separate attempt (which I didn’t publish in a repo or blog post), I managed to write a Cython function which was used as the callback parameter in the C function which is PET’s entry point. This callback mechanism was one of the main reasons I wrote most of Tadashi in C, I imagined it would be hard to interface Python code with ISL’s callback setup. Figuring out how to create callbacks in Cython I can more freely mix Python and C code, which would enable a sane way to organise code such that it includes both the current PET and future (Fortran enabled) LLVM/Polly backend.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>CI refers to <strong>Continuous Integration</strong> because CIBuildWheel is primarily used in CI, i.e., to automatically build wheels on, e.g., like GitHub using GitHub actions. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p><strong>Extensions</strong> are compiled, binary <code class="language-plaintext highlighter-rouge">.so</code> files which can be <code class="language-plaintext highlighter-rouge">import</code>ed into python scripts. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>A <strong>wheel</strong> Python package is a binary distribution (aka <strong>bdist</strong>) package, also containing binary files (such as .pyc/.so/.dll/.dylib files), in contrast to source distribution (aka <strong>sdist</strong>) packages, which contain only source files. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="programming"/><category term="tadashi"/><summary type="html"><![CDATA[A day of figuring out how to package Tadashi]]></summary></entry><entry><title type="html">[draft] SCoP detection</title><link href="https://vatai.github.io/blog/2025/scop-detection/" rel="alternate" type="text/html" title="[draft] SCoP detection"/><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2025/scop-detection</id><content type="html" xml:base="https://vatai.github.io/blog/2025/scop-detection/"><![CDATA[<h1 id="scop-detection">SCoP Detection</h1> <p>In the efforts to run <a href="/projects/tadashi">Tadashi</a> <a class="citation" href="#vatai2025tadashi">(Vatai et al., 2025)</a> on real world applications we developed <code class="language-plaintext highlighter-rouge">scop_detector</code> (and the convenience wrapper <code class="language-plaintext highlighter-rouge">scops_in_dir</code>) to help identify potential apps and/or SCoPs within them.</p> <h2 id="scop-detection-in-tadashi">SCoP detection in Tadashi</h2> <p>Tadashi extracts SCoPs from source files using PET <a class="citation" href="#verdoolaege2012polyhedral">(Verdoolaege &amp; Grosser, 2012)</a>. The entry point of PET is the <code class="language-plaintext highlighter-rouge">pet_transform_C_source()</code> function, which processes each SCoP by executing a callback function it passed to <code class="language-plaintext highlighter-rouge">pet_transform_C_source()</code> as a parameter.</p> <p>autodetect feature (in tadashi and in general)</p> <p><code class="language-plaintext highlighter-rouge">scop_detecor</code> similarly uses <code class="language-plaintext highlighter-rouge">pet_transform_C_source()</code>, but the callback, instead of transforming the scop, prints it as is with commented out <code class="language-plaintext highlighter-rouge">scop</code>/<code class="language-plaintext highlighter-rouge">endscop</code> pragmas (with an additional comment which indicates the index of the SCoP and makes it easier to locate the scops, like this</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
// #pragma scop // [N] //////////////////
&lt;SCoP&gt;
// #pragma endscop // [N] //////////////////
</code></pre></div></div> <p>This allows the user to just uncomment the pragmas for Tadashi to fin the SCoPs. However, care must be take: if you uncomment the scop/endscop pragmas with index 0 and 2 (but leave SCoP with index 1 commented out), this will result in Tadashi skipping SCoP 1 and messing up the index of the third SCoP and SCoP with index 2 (in the comment generated by <code class="language-plaintext highlighter-rouge">scop_detector</code>) will have index 1 in Tadashi.</p> <p>(setq display-line-numbers-type ‘visual)</p>]]></content><author><name></name></author><category term="programming"/><category term="tadashi"/><summary type="html"><![CDATA[SCoP Detection]]></summary></entry><entry><title type="html">[draft] SCoPing SNAP</title><link href="https://vatai.github.io/blog/2025/scoping-snap/" rel="alternate" type="text/html" title="[draft] SCoPing SNAP"/><published>2025-04-15T00:00:00+00:00</published><updated>2025-04-15T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2025/scoping-snap</id><content type="html" xml:base="https://vatai.github.io/blog/2025/scoping-snap/"><![CDATA[<h1 id="scoping-snap">SCoPing SNAP</h1> <p>This post describes my (ultimately failed) attempts to run <a href="/projects/tadashi">Tadashi</a> <a class="citation" href="#vatai2025tadashi">(Vatai et al., 2025)</a> on <a href="https://github.com/lanl/SNAP">SNAP</a>.</p> <h2 id="tldr">TL;DR</h2> <ul> <li>Detecting SCoPs</li> <li>The new error</li> <li>Running the pre-processor and lessons learned (aka PET uses ~clang~)</li> <li>Product of parameters error</li> <li>Macros simulating fortran arrays</li> <li>Ultimate failure and examples of non-SCoPs</li> </ul> <h2 id="scop-finding-utilities-scop_detector-and-scops_in_dir">SCoP finding utilities: <code class="language-plaintext highlighter-rouge">scop_detector</code> and <code class="language-plaintext highlighter-rouge">scops_in_dir</code></h2> <p>Tadashi relies on ISL and more accurately PET <a class="citation" href="#verdoolaege2012polyhedral">(Verdoolaege &amp; Grosser, 2012)</a> to extract the SCoP from a source file. It is not hard to write a utility which exclusively does this and instead of any serious polyhedral compilation it just gives a rough (or complete if time/space allows it)</p> <h1 id="old-stuff">Old stuff</h1> <p>In the search for realistic apps I wrote <code class="language-plaintext highlighter-rouge">scop_detector</code>, a very simple program which would run PET’s automatic scop detection algorithm on any given <code class="language-plaintext highlighter-rouge">.c</code> file, and print out the found schedule trees along with a summary (number of SCoPs, max depth of SCoPs, filename, etc.). Since this worked only on single files, a natural course of action was to add support for multiple files. This was achieved by wrapping it in a Bash script (<code class="language-plaintext highlighter-rouge">scops_in_dir</code>) which iterated (recursively) through all <code class="language-plaintext highlighter-rouge">.c</code> file in a directory and invoked <code class="language-plaintext highlighter-rouge">scop_detector</code> with them. This made “probing” projects for SCoPs trivial: clone/download the source code, run <code class="language-plaintext highlighter-rouge">scops_in_dir</code> and keep an eye out for a big/deep schedule tree. SNAP was one of the first apps which looked promising to extract SCoPs from!</p> <p><code class="language-plaintext highlighter-rouge">scop_detector</code> showed a deep schedule tree indicating multiple nested loops, which was promising, but it also printed an error which I saw for the first time saying “data dependent conditions not supported”. The error message was coming from code copied from <a href="https://repo.or.cz/ppcg.git">PPCG</a> <a class="citation" href="#verdoolaege2013polyhedral">(Verdoolaege et al., 2013)</a>, which was copied as part of the dead code elimination algorithm. The code revealed a loop with a boundary being a product of two parameters. It seemed that product can be calculated as a new SCoP parameter (before the SCoP). However, after the attempt to fix this issue the error still persisted.</p>]]></content><author><name></name></author><category term="programming"/><category term="tadashi"/><summary type="html"><![CDATA[SCoPing SNAP]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://vatai.github.io/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://vatai.github.io/blog/2025/plotly</id><content type="html" xml:base="https://vatai.github.io/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">MPI4py under Slurm</title><link href="https://vatai.github.io/blog/2025/mpi4py-with-slurm/" rel="alternate" type="text/html" title="MPI4py under Slurm"/><published>2025-02-11T00:00:00+00:00</published><updated>2025-02-11T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2025/mpi4py-with-slurm</id><content type="html" xml:base="https://vatai.github.io/blog/2025/mpi4py-with-slurm/"><![CDATA[<p>For <a href="/projects/tadashi">TADASHI</a> we are building a “benchmarking harness”, which would have a main instance running on one node of a cluster, and distribute to other nodes the code transformation (potentially), the compilation and the measurement of transformed apps.</p> <h1 id="benchmarking-harness-specifications">Benchmarking harness specifications</h1> <p>The key functionalities required by the harness are:</p> <ul> <li>it should have a python interface and</li> <li>it should distribute the benchmarking across nodes of a cluster/supercomputer.</li> </ul> <h1 id="candidate-solutions">Candidate solutions</h1> <p><a href="https://docs.celeryq.dev/en/stable/">Celery</a> and <a href="https://jolt.readthedocs.io/en/latest/">Jolt</a> came up as possible solutions, however we ended up trying only <a href="https://www.ray.io/">Ray</a> and <a href="https://mpi4py.readthedocs.io/en/stable/">MPI4py</a>.</p> <p>Both Ray and MPI4py had some sort of implementations for <a href="https://docs.python.org/3/library/concurrent.futures.html">Python futures</a>, and this looked like a good way to implement the benchmarking harness. I opted for MPI4py since it is a better fit for the MPI-based HPC clusters we have access to.</p> <p>The plan™ was to implement everything using Pythons <code class="language-plaintext highlighter-rouge">concurrent.futures</code> on my trusty little laptop, and then just swap out <code class="language-plaintext highlighter-rouge">concurrent.futures</code> with <code class="language-plaintext highlighter-rouge">mpi4py.futures</code>. But as it is often the case, life wasn’t so simple.</p> <h1 id="the-cluster-environment">The cluster environment</h1> <p>Also, as it is often the case, the required software is often not available on the cluster. So, the first round of crocodile wrestling was compiling a bunch of libraries and getting them all to work together. That was a pain in the neck, but doable.</p> <h1 id="the-wrench-in-the-gears-figuring-out-how-to-invoke-mpi4py-when-we-want-to-use-futures">The wrench in the gears: Figuring out (how to invoke) MPI4py when we want to use futures</h1> <p>After figuring Tadashi’s dependencies, the time came to “just swap out”™ <code class="language-plaintext highlighter-rouge">futures</code> (and <code class="language-plaintext highlighter-rouge">Executor</code>) from Python’s <code class="language-plaintext highlighter-rouge">concurrent</code> with MPI4py’s implementation.</p> <h2 id="the-right-mpi-which-supports-mpi_comm_spawn">The right MPI, which supports <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code></h2> <p>Something which came up earlier in the development of the benchmarking harness was <a href="https://en.wikipedia.org/wiki/Fugaku_(supercomputer)">Fugaku</a>’s support for master-worker jobs/workloads, which uses <a href="https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report/node289.htm#Node289"><code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code></a> to dynamically spawn processes, and incidentally, MPI4py <code class="language-plaintext highlighter-rouge">futures</code>, more precisely the <a href="https://mpi4py.readthedocs.io/en/stable/mpi4py.futures.html#mpipoolexecutor"><code class="language-plaintext highlighter-rouge">MPIPoolExecutor</code></a>, also uses <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code> under the hood. So it was a bit disappointing when I realised <a href="">OpenMPI doesn’t support <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code></a>. However, MPICH, which does support <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code>, was also available on the cluster and I just needed to recompile MPI4py with MPICH loaded to use it.</p> <h2 id="testing-went-well">Testing went well</h2> <p>Initially, it was a bit hard to wrap my head around how <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code> works, in my head <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code> is everything MPI is/can be aware of, but it turns out, if you have an allocation larger then <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code>, MPI still knows about it. This means, if you have an allocation of 10 nodes, you don’t lunch your master/parent program with <code class="language-plaintext highlighter-rouge">mpirun -n 10</code> but with <code class="language-plaintext highlighter-rouge">mpirun -n 1</code> and it will spawn processes on the remaining 9 nodes. So I logged in the cluster, got an interactive node, copy-pasted some example code for MPI4py spawn, and tested it – everything looked fine.</p> <h2 id="unwanted-behaviour--back-to-the-basics">Unwanted behaviour &amp; back to the basics</h2> <p>However, when I swapped <code class="language-plaintext highlighter-rouge">concurrent.futures</code> with <code class="language-plaintext highlighter-rouge">mpi4py.futures</code>, and wrote a submission script (to be launched by <code class="language-plaintext highlighter-rouge">sbatch</code>), things didn’t quite work. First, I realised the state of Tadashi which is in the binary <code class="language-plaintext highlighter-rouge">.so</code> files did not get pickled and transferred to the workers. After, temporarily disabling <code class="language-plaintext highlighter-rouge">.so</code> dependent code, I tried to rerun things, which did not fail!</p> <p>However, when, for some reason I remembered to check if the workers are actually being executed on different nodes, it turned out this is not the case: when checking <code class="language-plaintext highlighter-rouge">gethostname</code> both master and workers were executed on the same node (and the other allocated nodes remained idle).</p> <h2 id="3-ways-to-run-thing-in-slurm-and-finding-what-threw-the-wrench-in-the-gears">3 ways to run thing in Slurm, and finding what threw the wrench in the gears</h2> <p>Ultimately, the proverbial wrench in the gears, (aka bug, aka WTF) came down to the different ways you can launch programs with Slurm: using <code class="language-plaintext highlighter-rouge">srun</code>, <code class="language-plaintext highlighter-rouge">salloc</code> and <code class="language-plaintext highlighter-rouge">sbatch</code>.</p> <p><code class="language-plaintext highlighter-rouge">srun</code> allocates you resources from a cluster, and runs your binary (I like to think about <code class="language-plaintext highlighter-rouge">srun</code> as <code class="language-plaintext highlighter-rouge">mpirun</code>, but it is “aware” of the resources). <code class="language-plaintext highlighter-rouge">salloc</code> doesn’t run the program, it just allocates resources, and if a command is provided it executes that command only once, i.e. not on all nodes. To utilise all nodes within an allocation obtained by <code class="language-plaintext highlighter-rouge">salloc</code>, one would call <code class="language-plaintext highlighter-rouge">srun</code>. Finally, <code class="language-plaintext highlighter-rouge">sbatch</code> is like <code class="language-plaintext highlighter-rouge">srun</code> but instead of getting the allocation and running it immediately (dumping stdout to the terminal), <code class="language-plaintext highlighter-rouge">sbatch</code> puts the job/command in the queue, and saves the output into a <code class="language-plaintext highlighter-rouge">slurm-*.out</code> file.</p> <h2 id="getting-it-right">Getting it right</h2> <p>To get to the bottom of things, I ended up writing a (pair of) simple MPI programs, <code class="language-plaintext highlighter-rouge">spawn_main.c</code> and <code class="language-plaintext highlighter-rouge">spawn_child.c</code>, each reporting the hostname. And again I made the mistake of running things from an interactive node, which I obtained using <code class="language-plaintext highlighter-rouge">srun -N 3 -p genoa --pty bash</code>. From thin interactive instance, running <code class="language-plaintext highlighter-rouge">mpirun -N 1 ./spawn_main</code> gave the desired results: the main and child processes were all reporting different hostnames.</p> <p>The moment of clarity came when I wanted to present the full example, and wrote a <code class="language-plaintext highlighter-rouge">spawn_submit.sh</code> submission script, which I launched with <code class="language-plaintext highlighter-rouge">sbatch</code>. Lo and behold, I was back to the undesired behaviour of both main and child instances reporting the same hostname! This meant, that calling <code class="language-plaintext highlighter-rouge">mpirun -N 1 ./spawn_main</code> didn’t do the same thing when called from a submission script and when called from an interactive session.</p> <p>I tried emulating the interactive session by running <code class="language-plaintext highlighter-rouge">mpirun</code> inside <code class="language-plaintext highlighter-rouge">bash</code> inside <code class="language-plaintext highlighter-rouge">srun</code>, i.e.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>srun bash -c 'mpirun -N 1 ./spawn_main`
</code></pre></div></div> <p>The results was a new kinda of undesired behaviour. Now <code class="language-plaintext highlighter-rouge">mpirun</code> saw all the allocated nodes and processes were reporting different hostnames, but each hostname was printed 3 times. It seems <code class="language-plaintext highlighter-rouge">srun</code> executed <code class="language-plaintext highlighter-rouge">mpirun</code> 3x, but oddly enough the main process was always on the same node (i.e. not on all 3 nodes for the 3x execution of <code class="language-plaintext highlighter-rouge">srun</code>).</p> <p>I obtained the first working solution by adding another <code class="language-plaintext highlighter-rouge">if</code> to the monstrosity above which checked the “slurm rank”, i.e.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>srun bash -c '[ $SLURM_NODEID = 0 ] &amp;&amp; mpirun -N 1 ./spawn_main || true'
</code></pre></div></div> <p>Calling <code class="language-plaintext highlighter-rouge">mpirun</code> inside <code class="language-plaintext highlighter-rouge">srun</code> already felt wrong, and the added complications didn’t improve the situation, so after some googling I fond an <a href="https://stackoverflow.com/questions/74160847/spawning-child-processing-on-hpc-using-slurm">SO question</a> asking about launching <code class="language-plaintext highlighter-rouge">MPI_Comm_spawn</code> from slurm, and copied the batch script parameters from there and it worked.</p> <p>It turns out, the missing ingredient was a missing <code class="language-plaintext highlighter-rouge">-n 3</code> for the job allocation. The final working solution looks like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/usr/bin/bash
#SBATCH -p genoa
#SBATCH -N 3
#SBATCH -n 3
#SBATCH -c 1

# ... snip ...

mpirun -N 1 spawn_main
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">-N</code> is the number of nodes allocated, <code class="language-plaintext highlighter-rouge">-n</code> is the number of tasks (i.e. number of MPI ranks). The solution is valid without <code class="language-plaintext highlighter-rouge">-c 1</code> (number of CPUs per task/rank), but I left it in just in case.</p>]]></content><author><name></name></author><category term="programming"/><category term="tadashi"/><summary type="html"><![CDATA[For TADASHI we are building a “benchmarking harness”, which would have a main instance running on one node of a cluster, and distribute to other nodes the code transformation (potentially), the compilation and the measurement of transformed apps.]]></summary></entry><entry><title type="html">Making Tadashi into a Python package</title><link href="https://vatai.github.io/blog/2025/making-tadashi-into-a-python-package/" rel="alternate" type="text/html" title="Making Tadashi into a Python package"/><published>2025-01-04T00:00:00+00:00</published><updated>2025-01-04T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2025/making-tadashi-into-a-python-package</id><content type="html" xml:base="https://vatai.github.io/blog/2025/making-tadashi-into-a-python-package/"><![CDATA[<h1 id="the-current-situation">The current situation</h1> <p>Currently, to run Tadashi, you need to compile some .so files first with CMake. It needs to be built into the <code class="language-plaintext highlighter-rouge">build</code> directory under the project root. Finally, adding the project root to <code class="language-plaintext highlighter-rouge">PYTHONPATH</code> will allow python to find both the python files and the binary .so files.</p> <h2 id="swig">SWIG</h2> <p>First thing to clean up was implementing SWIG instead the ad-hoc CDLL approach currently used to call the C/C++ functions from Python. CDLL takes the path of the .so file, which is hard-coded in the Python files (hence the ad-hoc character of the implementation). CDLL also requires the arguments and return values of the functions exposed to Python from the .so files need to be copied from the .h files manually.</p> <p>The SWIG implementation has the following advantages:</p> <ul> <li>The arguments and return values of the functions are automagically generated based on the .h files, thus letting us have a single source of truth (well, technically two, since the function prototypes in .h and .cc need to be synced manually, but the compiler catches any discrepancies).</li> <li>SWIG generates the wrapper Python file in the same directory as the .so file (as part of the build process), eliminating the need to manually specify the path to the .so.</li> </ul> <h2 id="building-a-python-package">Building a Python package</h2> <p>To the best of my knowledge, the way to do python packages is to write a <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file. However, <code class="language-plaintext highlighter-rouge">pyproject.toml</code> does not support build extensions and they must be configured in <code class="language-plaintext highlighter-rouge">setup.py</code>. The <code class="language-plaintext highlighter-rouge">cmake-build-extension</code> build extension invokes CMake as part of the build process of the wheel.</p> <p>TODO</p> <ul> <li>double check</li> </ul> <hr/> <ul> <li>Python package</li> <li>cmake-build-extension</li> </ul> <h1 id="the-new-problems">The new problems</h1> <hr/>]]></content><author><name></name></author><category term="programming"/><category term="tadashi"/><summary type="html"><![CDATA[The current situation]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://vatai.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://vatai.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://vatai.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">[DRAFT] Flattening loops of combinations, again!?</title><link href="https://vatai.github.io/blog/2024/flattening-loops-again/" rel="alternate" type="text/html" title="[DRAFT] Flattening loops of combinations, again!?"/><published>2024-12-03T00:00:00+00:00</published><updated>2024-12-03T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2024/flattening-loops-again</id><content type="html" xml:base="https://vatai.github.io/blog/2024/flattening-loops-again/"><![CDATA[<p>We had problems implementing the 3x1 flattened four nested loops generating 4-combinations in <a class="citation" href="#dash2021scaling">(Dash et al., 2021)</a>.</p> \[\begin{align*} q &amp;\gets (\sqrt{729 \lambda^2 -3} + 27 \lambda)^{1/3} \\ k &amp;\gets \lfloor (q/3^2)^{1/3} + 1/(3q)^{1/3} - 1 \rfloor \\ T_z &amp;\gets k (k + 1) (k + 2) / 6 \\ \lambda' &amp;= \lambda - T_z \\ j &amp;\gets \lfloor \sqrt{1/4 + 2\lambda'} -1/2 \rfloor \\ i &amp;\gets \lambda' - j (j + 1) / 2 \end{align*}\]]]></content><author><name></name></author><category term="programming"/><summary type="html"><![CDATA[We had problems implementing the 3x1 flattened four nested loops generating 4-combinations in (Dash et al., 2021).]]></summary></entry><entry><title type="html">Flattening loops of combinations</title><link href="https://vatai.github.io/blog/2024/flattening-loops-of-combinations/" rel="alternate" type="text/html" title="Flattening loops of combinations"/><published>2024-11-11T00:00:00+00:00</published><updated>2024-11-11T00:00:00+00:00</updated><id>https://vatai.github.io/blog/2024/flattening-loops-of-combinations</id><content type="html" xml:base="https://vatai.github.io/blog/2024/flattening-loops-of-combinations/"><![CDATA[<p>In <a class="citation" href="#dash2021scaling">(Dash et al., 2021; Al Hajri et al., 2020)</a>, when iterating through all 2-hit combinations (of \(G\) number of genes), the outer two \(i\) and \(j\) loops are “flattened” into a single \(\lambda\) loop (\(\lambda \gets 1\ldots\binom{G}{2}\)). To reconstruct the \(i\) and \(j\) the following formulas are used:</p> \[\begin{align} j &amp;= \lfloor \sqrt{1/4 + 2 \lambda} + 1/2 \rfloor \\ i &amp;= \lambda - j (j - 1) / 2 \end{align}\] <p>Let’s try to derive those formulas.</p> <p>It is easy to spot the \(S_{j-1} := \sum_{t=1}^{j-1} t = \frac{j (j - 1)}{2}\) formula for the sum of all positive integers going up to \(j-1\). Which leads us to:</p> \[\lambda = i + \frac{j(j - 1)}{2} = i + \sum_{t=1}^{j-1} t\] <p>The same \(S_{j-1}\) formula is also present in the expression for \(j\) (we begin by removing the \(\lfloor \cdot \rfloor\)):</p> \[\begin{align} j &amp;= \sqrt{1/4 + 2 \lambda} + 1/2 \\ j - 1/2 &amp;= \sqrt{1/4 + 2 \lambda} \\ (j - 1/2)^2 &amp;= 1/4 + 2 \lambda \\ j^2 - j + 1/4 &amp;= 1/4 + 2 \lambda \\ j^2 - j &amp;= 2 \lambda \\ \lambda &amp;= \frac{j (j-1)}{2} \end{align}\] <p>According to <a class="citation" href="#dash2021scaling">(Dash et al., 2021; Al Hajri et al., 2020)</a> this flattened \(\lambda\) loop corresponds to the following \(i\) and \(j\) loop:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 : 0 1
2 : 0 2
3 : 0 3
4 : 0 4
5 : 1 2
6 : 1 3
7 : 1 4
8 : 2 3
9 : 2 4
10 : 3 4
</code></pre></div></div> <p>If we implement the flattened loop we see that this is only true in the sense that the set of visited combination is the same, however, the order is different.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">math</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">Nc2</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">Nc2</span><span class="p">):</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">L</span> <span class="o">-</span> <span class="n">j</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 : 0 1
1 : 0 2
2 : 1 2
3 : 0 3
4 : 1 3
5 : 2 3
6 : 0 4
7 : 1 4
8 : 2 4
9 : 3 4
</code></pre></div></div> <p>So to generate the combinations in the same order as the initial \(i\), \(j\) loops, we need to modify the code as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">math</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">Nc2</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="nf">reversed</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">Nc2</span><span class="p">)):</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">L</span> <span class="o">-</span> <span class="n">j</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="p">,</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9 : 0 1
8 : 0 2
7 : 0 3
6 : 0 4
5 : 1 2
4 : 1 3
3 : 1 4
2 : 2 3
1 : 2 4
0 : 3 4
</code></pre></div></div> <p>Or alternatively, if we want to modify the original \(i\), \(j\) loop to match the \(\lambda\) loop and the mathematical derivation:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 : 0 1
2 : 0 2
3 : 1 2
4 : 0 3
5 : 1 3
6 : 2 3
7 : 0 4
8 : 1 4
9 : 2 4
10 : 3 4
</code></pre></div></div> <h1 id="graphical-representation">Graphical representation</h1> <script type="text/tikz">
\begin{tikzpicture}

% GRAY
\foreach \i in {0,1,2,3,4}
  \foreach \j in {0,1,2,3}
    \node at (\i, \j) [draw, lightgray, circle]{};

% RED
\foreach \j [evaluate=\j as \jj using int(\j-1)] in {1,2,3}
  \foreach \i in {\jj,...,0}
    \node at (\j, \i) [fill, blue, circle]{};
\foreach \i in {0,1} \node at (4,\i) [fill, red, circle]{};

% labels
\node at (-1,-1) [anchor=east]{$\lambda=\frac{j(j-1)}{2}+i=6+1$};
\node at (-1,1) [draw]{$i=1$};
\node at (4,-1) [draw]{$j=4$};
\foreach \i in {0,2,3} \node at (-1,\i) {$\i$};
\foreach \j in {0,1,...,3} \node at (\j,-1) {$\j$};

\end{tikzpicture}
</script> <p>Because \(\lambda \mapsto j(\lambda) = \lfloor \sqrt{1/4 + 2 \lambda} + 1/2 \rfloor\) is monotonically increasing (non-decreasing), returning the \(\lfloor \cdot \rfloor\) which we skipped in the calculations above, means that \(j\) is the largest possible integer such that \(\lambda = i + \frac{j(j - 1)}{2}\) for a non-negative integer \(i\). In the figure we can read \(j=4\) since the blue dots represent \(\sum_{t=1}^{j-1} t\) and the red dots show the calculation of \(i = \lambda - \sum_{t=1}^{j-1} t\).</p>]]></content><author><name></name></author><category term="programming"/><summary type="html"><![CDATA[In (Dash et al., 2021; Al Hajri et al., 2020), when iterating through all 2-hit combinations (of \(G\) number of genes), the outer two \(i\) and \(j\) loops are “flattened” into a single \(\lambda\) loop (\(\lambda \gets 1\ldots\binom{G}{2}\)). To reconstruct the \(i\) and \(j\) the following formulas are used:]]></summary></entry></feed>